\section{Spreads de Contrat CDS} 
\subsection{Données}
    \subparagraph{} Les données fournies sont des cotations de spreads de CDS pour les maturités
    allant de 1ans à 10ans, entre 16/08/2005 et
    30/09/2010. 
    Cette période a été marque par le début de la crise financière en 2008, et en
    particulier par la faillite de la filiale new-yorkaise de la société AIG le 16
    septembre 2008. 
    \subparagraph{}
    Le marché des CDS est considérée comme une des raisons principales de la chute
    du groupe Américain AIG.En effet, Le marché des CDS est passé de 6 396 milliards de dollars
    américains à fin 2004 à 57 894 milliards à fin 2007, prenant le caractère d'une
    bulle financière.

    
    \begin{verbatim}
    > head(data)
                        cot       S1  S2  S3  S4   S5   S6   S7   S8   S9  S10
               700 2008-04-21 1.960095 7.9 8.3 9.2 10.0 10.7 11.4 12.0 12.6 13.1
               701 2008-04-22 1.791759 6.7 7.1 7.8  8.5  9.3 10.2 11.0 11.9 12.8
               702 2008-04-23 1.791759 6.7 7.1 7.8  8.5  9.3 10.1 11.0 11.8 12.7
               703 2008-04-24 1.757858 6.5 6.8 7.5  8.2  9.0  9.7 10.5 11.3 12.1
               704 2008-04-25 1.629241 5.7 6.0 6.6  7.2  8.0  8.8  9.8 10.7 11.6
               705 2008-04-28 1.648659 5.8 6.1 6.7  7.3  8.0  8.7  9.4 10.1 10.8
    \end{verbatim}

    \subsection{Chronogramme} 
    Notre première étape est donc de voir l'allure de la courbe :
    \begin{figure}[H]
        \centering
        \label{fig:chrono} 
        \includegraphics[width=3in,heigth=3in,angle=270]{chrono} 
        \caption{\it Le Chronogramme des spreads de maturité 1 ans } 
    \end{figure}

    On remarque bien que la variance de la courbe augmente avec le temps. Cela
    montre de premier abord que le processus n'est pas stationnaire, autrement
    on aurait eu une variation stable au long du processus.

    On constate aussi une croissance importante du processus, et cela favorise bien
    l'existence d'une tendance croissante.

    \subsection{Stabilisation la variance}
        L'augmentation de la variance au fil du temps peu être diminue grâce a
        certaines transformation. Nous allons choisir celle  de Box-Cox définie par :
        \[
            f_\lambda(X_t)=
            \begin{cases}
                \lambda^{-1}(X_t^\lambda - 1), & X_t \geq 0,\lambda \ge 0, \\
                \ln X_t,                       & X_t \ge  0,\lambda  =   0,
            \end{cases}
        \]
        pour cela comparons les transformations pour les valeurs de
        $\lambda=0,0.5,1.5$
        \begin{figure}[H]
            \centering 
            \label{fig:Boxcox} 
            \includegraphics[width=4in,heigth=4in,angle=270]{boxcox} 
            \caption{\it Trace des spreads de 1 ans en appliquant les
            transformation de Box-Cox pour 3 valeurs de $\lambda$ } 
        \end{figure} 
        On remarque que la transformation logarithmique est bien adaptée  aux
        données car elle diminue l'effet de la croissance de la variance.\\
        Ainsi dans la suite on choisira de travailler sur cette transformation
        $\ln(X_t)$


        \subsection{Étude de la saisonnalité et de la tendance}

    \paragraph{}Dans ce paragraphe nous allons voire si on peut détecter une saisonnalité.
    Commençons alors par tracer le périodogramme :
    \begin{figure}[h]
        \centering 
        \label{fig:period} 
        \includegraphics[width=3in,heigth=3in,angle=270]{period} 
        \caption{\it périodogramme de la période 2008-04-21 - 2008-07-11 } 
    \end{figure} 

    Le périodogramme ne nous informe pas sur une probable saisonnalité.

        \subsubsection{Agrégation annuelle}
            Pour avoir une idée plus claire sur le comportement annuel du
            processus nous allons tracer la moyenne des spreads par année :
            \begin{figure}[H]
                \centering 
                \label{fig:annual} 
                \includegraphics[width=3in,heigth=3in,angle=270]{Annual} 
                \caption{\it Agrégation annuelle des spreads par moyenne empirique } 
            \end{figure} 
             la société AIG a dû
            augmenter les niveau des spreads parce que les
            entités de référence présentaient plus de risque  en période de
            crise. 

        % \subsubsection{Agregation mensuelle}
        %     Pour voir le comportement des spreads mensuelle on va les agreger par
        %     moyenne empirique  

        %     \begin{figure}[H]
        %         \centering 
        %         \label{fig:meanMens} 
        %         \includegraphics[width=4in,heigth=4in,angle=270]{meanMens} 
        %         \caption{\it Moyenne par mois sur toutes les années pour les spreads
        %         de 1 ans } 
        %     \end{figure} 

        %     Le graphique des boxplots montre une certaine homogenite de distribution sur
        %     les mois, donc on en conclut que les données non pas une saisonnalité
        %     mensuelle particulière.

            \subsubsection{Superposition des spreads par année} 
            On va superposer les spreads
        \begin{figure}[H]
            \centering 
            \label{fig:polarAn} 
            \includegraphics[width=3in,heigth=3in,angle=270]{polarAn} 
            \caption{\it Représentation polaire de les spreads } 
        \end{figure} 


        \subparagraph{}     On constate bien que les points s'éloignent du centre d'année en
        année, ce qui traduit la tendance croissante du processus. En outre
        il n'y a pas de symétrie entre l'allure des spreads par année ce qui
        rend la présence d'une saisonnalité encore moins évident.Cette dernière
        observation nous dirige vers l'approbation  d'une
        absence de saisonnalité.  

        \subparagraph{} La fonction \verb+decompose()+  en R permet de décomposer le processus en
        tendance et saisonnalité, alors que \verb+nsdiffs+ calcul le nombre de
        différenciation nécessaires pour desaisonnaliser le processus :
        \begin{verbatim}
        > decompose(S1)
        Erreur dans decompose(S1) : la srie temporelle a moins de 2 priodes
        \end{verbatim}

        \begin{verbatim}
        > nsdiffs(S1)
        Erreur dans nsdiffs(S1) : Non seasonal data
        \end{verbatim}


        \subparagraph{Conclusion}
        Sur ces résultats nous concluons que le processus ne présente aucune
        saisonnalité mais une tendance croissante.
           
\subsection{Modélisation du processus}
    \subsubsection{Étude des propriétés du processus}    
        \paragraph{Indépendance} 
        le processus est loin d'être un processus indépendant, car certainement la
        société n'est pas indifférente aux spreads qu'elle a émise dans le passe.
        Pour tester l'indépendance on choisit par exemple le test de Portemanteau
        qui est fourni par R sous \verb+Box.test()+ avec $H_0$=\"le processus est
        indépendant\". Le test calcul
        la distance $\xi^2$ de l'auto-covariance des premiers retards. Si la p-value est très petite ce la
        veut dire que cette auto-covariance n'est pas nulle et donc le processus :
        \begin{verbatim}
        > Box.test (S1)

        Box-Pierce test

        data:  S1
        X-squared = 1327.591, df = 1, p-value < 2.2e-16

        > Box.test (S1,  type = ``Ljung'')

        Box-Ljung test

        data:  S1
        X-squared = 1330.57, df = 1, p-value < 2.2e-16

        \end{verbatim}

        Le test retourne une p-value presque nulle donc on rejette hypothèse nulle.
        Ainsi le processus n'est pas indépendant.

        \paragraph{Stationnarité}
        Un processus stationnaire est un processus dont :
        \begin{itemize}
            \item $\forall t,E[X_t]=\mu$  
            \item $cov(X_{t+h},X_t)=\gamma(h)$ 
        \end{itemize}
        Ceci implique que le processus a une variance constante .
        Notre processus donc ne peut être stationnaire du fait de la crise
        financière qui a eu un grand impact sur les CDS. 

        \paragraph{} Pour tester la stationnarité de notre processus nous utiliserons les tests
        de la racine unité. 
        La fonction \verb+adf.test()+ permet de faire le test de Dickey Fuller
        où l'hypothèse nulle est la non stationnarité du processus.  
        \begin{verbatim}
        > adf.test(x = S1,alternative = ``s'')

        Augmented Dickey-Fuller Test

        data:  S1
        Dickey-Fuller = -3.0033, Lag order = 11, p-value = 0.1536
        alternative hypothesis: stationary
        \end{verbatim}

        Le test a donc une p-value non négligeable donc on ne peut pas rejeter
        l'hypothèse nulle de non stationnarité 
        
        \paragraph{Fonction d'autocorrélation} traçons maintenant la fonction
        d'autocorrélation absolue et partielle :
        \begin{figure}[H]
            \centering 
            \label{fig:ac} 
            \includegraphics[width=4in,heigth=4in,angle=270]{ac} 
            \caption{\it Corrélogramme } 
        \end{figure} 

        \paragraph{}l'ACF est décroissante, donc la tendance de ce processus
        pourrai bien être une tendance polynomiale. 
        

    \subsection{Élimination de la tendance}
        \paragraph{} Les tendances polynomiale disparaissent après un nombre de
        différenciation au minimum égale au degré polynomiale de cette tendance.
        Nous allons commencer par une différenciation d'ordre 1. Notons $Y_t=\Delta X_t$
        traçons l'allure de cette différence :

        \begin{figure}[H]
            \centering 
            \label{fig:chronoD1} 
            \includegraphics[width=3in,heigth=3in,angle=270]{chronoD1} 
            \caption{\it Allure de la différence du processus $X_t$ } 
        \end{figure} 

        On remarque de visu que le processus est centre. Cela peut être confirme par
        le test de Student :
        \begin{verbatim}
        > t.test(D1,mu = 0)

            One Sample t-test

            data:  D1
            t = 1.1398, df = 637, p-value = 0.2548
            alternative hypothesis: true mean is not equal to 0
            95 percent confidence interval:
             -0.002115699  0.007969121
             sample estimates:
               mean of x 
               0.002926711 

        \end{verbatim}
        On ne peut pas rejeter donc l'hypothèse nulle qui est que le processus
        est centre.
        \paragraph{Test d'indépendance}

        \begin{verbatim}
        > Box.test(x = D1)

        Box-Pierce test

        data:  D1
        X-squared = 11.272, df = 1, p-value = 0.0007869

        > Box.test(x = D1,type = ``L'')

        Box-Ljung test

        data:  D1
        X-squared = 11.2973, df = 1, p-value = 0.0007762

        \end{verbatim}
        
        La p-value du test étant tres faible on peut rejeter l'hypothèse nulle
        d'intendance : le processus dépend toujours du passe.
        \paragraph{Stationnarité}
    
        En appliquant le test de Dickey-Fuller :
        \begin{verbatim}
        > adf.test(x = D1,alternative = ``s'') # -> processus stationnaire

        Augmented Dickey-Fuller Test

        data:  D1
        Dickey-Fuller = -11.0561, Lag order = 11, p-value = 0.01
        alternative hypothesis: stationary

        Message d'avis :
        In adf.test(x = D1, alternative = ``s'') :
        p-value smaller than printed p-value
        \end{verbatim}
        Le test renvoie une p-value très faible donc on peut rejeter l'hypothèse
        nulle : le processus $Y_t$ est stationnaire.

        À présent on peut envisager une modélisation ARMA pour le processus
        $Y_t$.
    \subsection{Modélisation ARMA}        
        
        Examinons d'abord l'allure de d'autocorrélation de ce processus:
        \begin{figure}[H]
            \centering 
            \label{fig:D1ac} 
            \includegraphics[width=3in,heigth=3in,angle=270]{D1ac} 
            \caption{\it autocorrélation totale et partielle de $Y_t$ } 
        \end{figure} 

        On constate tout d'abord que l'ACF et la PACF s'annulent à partir du
        deuxième
        retard. Donc cela nous suggère immédiatement trois modèle ARMA qui peuvent
        être candidats : ARMA(0,1), ARMA(1,0) et ARMA(1,1)
        Comparons alors ces trois modèles en utilisant le critère AIC :

        \begin{verbatim}
        > arima(s1,c(0,1,1))
        Series: x 
        ARIMA(0,1,1)                    

        Coefficients:
        ma1
        0.1231
        s.e.  0.0381

        sigma^2 estimated as 0.004142:  log likelihood=844.96
        AIC=-1687.92   AICc=-1687.9   BIC=-1679

        > arima(s1,c(1,1,0))
        Series: x 
        ARIMA(1,1,0)                    

        Coefficients:
        ar1
        0.1308
        s.e.  0.0394

        sigma^2 estimated as 0.004137:  log likelihood=845.29
        AIC=-1688.58   AICc=-1688.56   BIC=-1679.67
        > arima(s1,c(1,1,1))
        Series: x 
        ARIMA(1,1,1)                    

        Coefficients:
        ar1      ma1
        0.2877  -0.1593
        s.e.  0.2465   0.2534

        sigma^2 estimated as 0.004135:  log likelihood=845.47
        AIC=-1686.94   AICc=-1686.9   BIC=-1673.56
        \end{verbatim}

        La modélisation est clairement meilleure au niveau de la minimisation du
        critère AIC et BIC. Cela aussi est confirme par la fonction
        \verb+auto.arima()+ :
        \begin{verbatim}
        > auto.arima(x = s1,d = 1,max.p = 5,max.q = 5,start.p = 0,start.q =
        0,allowdrift = TRUE,trace = TRUE,ic = ``aic'',seasonal = FALSE)

        ARIMA(0,1,0) with drift         : -1671.466
        ARIMA(0,1,0) with drift         : -1671.466
        ARIMA(1,1,0) with drift         : -1686.102
        ARIMA(0,1,1) with drift         : -1679.346
        ARIMA(2,1,0) with drift         : -1683.538
        ARIMA(1,1,1) with drift         : -1684.192
        ARIMA(2,1,1) with drift         : -1681.549
        ARIMA(1,1,0)                    : -1686.863
        ARIMA(0,1,0)                    : -1672.167
        ARIMA(2,1,0)                    : -1684.384
        ARIMA(1,1,1)                    : -1684.962
        ARIMA(2,1,1)                    : -1682.392

        Best model: ARIMA(1,1,0)                    

        Series: s1 
        ARIMA(1,1,0)                    

        Coefficients:
        ar1
        0.1308
        s.e.  0.0394

        sigma^2 estimated as 0.004137:  log
        likelihood=845.29
        AIC=-1686.58   AICc=-1686.56   BIC=-1677.67
        \end{verbatim}
        Pour finir testons la précision du coefficient ar1 par un test
        t-statistic :
        \begin{verbatim}
                    ar1
                    t.stat 3.317992
                    p.val  0.000907
        \end{verbatim}
        la p-value est très faible donc le coefficient est précis.
        \paragraph{Résidu}
            \subparagraph{}
            \begin{verbatim}
            > t.test(M0$residuals)$p.value
            [1] 0.3169825
            \end{verbatim}
            la p-value étant très grande on peut dire que le résidu est
           centre. 
            \subparagraph{Indépendance}
                \begin{verbatim}
                > Box.test(M0$residuals)$p.value
                [1] 0.8762552
                \end{verbatim}
                La p-value du test de Portemanteau étant très grande on peux dire
                que le résidus est indépendant.
            \subparagraph{Stationnarité}
                \begin{verbatim}
                    > adf.test(x = M0$residuals,alternative = ``s'')$p.value
                    [1] 0.01
                    Message d'avis :
                    In adf.test(x = M0$residuals, alternative = ``s") :
                      p-value smaller than printed p-value
                \end{verbatim}
                La p-value du test de non  stationnarité est très faible donc on
                peut rejeter l'hypothèse de non stationnarité : Le résidu est
                bien stationnaire

\section{Étude du cours d'action de la société AIG}
    \subsection{Exploration des données}
        \begin{verbatim}    
        > describe(aig)
        aig 

         2  Variables      491  Observations
         --------------------------------------------------------------------------------------------------
         cot 
               n missing  unique 
                   491       0     491 

                   lowest : 2013-01-28 2013-01-29 2013-01-30 2013-01-31
                   2013-02-01
                   highest: 2014-12-31 2015-01-02 2015-01-05 2015-01-06
                   2015-01-07 
                   --------------------------------------------------------------------------------------------------
                   cours 
                         n missing  unique    Info    Mean     .05     .10
                         .25     .50     .75     .90     .95 
                             491       0     424       1   49.18   38.41   39.21
                             46.44   49.81   53.52   55.08   55.58 

                             lowest : 37.06 37.28 37.30 37.57 37.67, highest:
                             56.33 56.42 56.44 56.49 56.51 
                             --------------------------------------------------------------------------------------------------
        \end{verbatim}
        \begin{figure}[H]
            \centering 
           \label{fig:Aigchrono} 
            \includegraphics[width=3in,heigth=3in,angle=270]{Aigchrono} 
            \caption{\it Trace du Chronogramme du cours d'action d'AIG entre
            2007-09-28 et 2010-09-30} 
        \end{figure} 

    \subsection{Stabilisation de la variance}                

        Comme dans la section précédente on va transformer nos données
        logarithmiquement afin d'avoir une variabilité un peu plus
        stable :
        \begin{figure}[H]
            \centering 
            \label{fig:Aiglog} 
            \includegraphics[width=3in,heigth=3in,angle=270]{Aiglog} 
            \caption{\it Transformation logarithmique du cours
            d'action de AIG } 
        \end{figure} 

        % \subsection{Modelisation}
            % \subsubsection{Ordre de differenciation}
            % % \paragraph{Remarque} Le premier ordre de differenciation corresponds au rendement de
            %     l'action AIG. En effet :
            %     \[
            %         \Delta \log X_t ~ \frac{X_t - X_{t-1}}{X_t}
            %     \]
            % \paragraph{Stationnarite du processus differencie}
            %     \begin{figure}[H]
            %         \centering 
            %         \label{fig:Aigdep} 
            %         \includegraphics[width=3in,heigth=3in,angle=270]{Aigdep} 
            %         \caption{\it Correlogramme du processus
            %         differencie ou du rendement  } 
            %     \end{figure} 

            %     On constate que le rendement est centre, avec presque aucune
            %     autocorrelation non nulle.
            %     \begin{verbatim}
            %     > summary(ur.kpss(y = l.aig$R))

            %     ####################### 
            %     # KPSS Unit Root Test # 
            %     ####################### 

            %     Test is of type: mu with 6 lags. 

            %     Value of test-statistic is: 0.5453 

            %     Critical value for a significance level of: 
            %                     10pct  5pct 2.5pct  1pct
            %     critical values 0.347 0.463  0.574 0.739

            %     \end{verbatim}
            %     Ainsi on ne peut pas trancher sur la stationnarite du rendement.
            %     J'ai essaye alors de pousser la differentiation a un ordre plus
            %     superieur mais le resultat pour la stationnarite reste le même.
            %     Donc on retient le premier ordre de differenciation. 

    \subsection{Modélisation ARMA}       
        \paragraph{Élimination de la tendance par différenciation } Examinons le 2
        ème ordre de différenciation :
        \begin{figure}[H]
            \centering 
            \label{fig:Aigdep} 
            \includegraphics[width=3in,heigth=3in,angle=270]{Aigdep} 
            \caption{\it Corrélogramme du processus $\Delta_2 X_t$ } 
        \end{figure} 
        \begin{verbatim}
        > summary(ur.kpss(diff(l.aig$cours,2)))

        ####################### 
        # KPSS Unit Root Test # 
        ####################### 

        Test is of type: mu with 5 lags. 

        Value of test-statistic is: 0.0469 

        Critical value for a significance level of: 
                        10pct  5pct 2.5pct  1pct
        critical values 0.347 0.463  0.574 0.739
        \end{verbatim}
        Le processus $\Delta_2 X_t$ est bien stationnaire puisque le test KPSS renvoie une
        test-statistic inférieur à toutes les valeurs critiques.
        \paragraph{Estimation de l'ordre de ARIMA} Le corrélogramme montre que
        la ACF s'annule  à partir du deuxième retard alors que la PACF décroit
        exponentiellement donc il s'agit fort probablement d'un ARIMA(0,2,1). 
        En effet c'est le meilleur modèle suivant le critère AIC:
        \begin{verbatim}
        > AIC(arima(x = l.aig$cours,order = c(0,2,1)))
        [1] -1566.877
        > AIC(arima(x = l.aig$cours,order = c(1,2,1)))
        [1] -1565.676
        > AIC(arima(x = l.aig$cours,order = c(2,2,1)))
        [1] -1564.369
        > AIC(arima(x = l.aig$cours,order = c(3,2,1)))
        [1] -1563.706
        > AIC(arima(x = l.aig$cours,order = c(4,2,1)))
        [1] -1562.007
        > AIC(arima(x = l.aig$cours,order = c(5,2,1)))
        [1] -1561.49
        \end{verbatim}
        \paragraph{Étude du résidu} Pour confirmer notre modélisation il faut
        vérifier que le bruit est un bruit faiblement stationnaire .
        \begin{figure}[H]
            \centering 
            \label{fig:Aigres} 
            \includegraphics[width=3in,heigth=3in,angle=270]{Aigres} 
            \caption{\it Corrélogramme du résidu de la modélisation ARIMA(0,2,1) } 
        \end{figure} 

        D'après le corrélogramme, on constate que toutes les autocorrélation
        sont nulle avec une confiance de 95\%.
        Nous allons soutenir cette hypothèse par un test de stationnarité :
        \begin{verbatim}
        > summary(ur.kpss(resid))

        ####################### 
        # KPSS Unit Root Test # 
        ####################### 

        Test is of type: mu with 5 lags. 

        Value of test-statistic is: 0.0619 

        Critical value for a significance level of: 
                        10pct  5pct 2.5pct  1pct
        critical values 0.347 0.463  0.574 0.739
        \end{verbatim}
        En effet le test rejette l'hypothèse de non stationnarité des résidus.
        Ainsi on peut dire que le résidu est faiblement stationnaire.
    \subsection{Prédiction}
    \paragraph{Prédiction pas à pas} Comme précédemment on prédit a chaque date
    le prochain cours :
    \begin{figure}[H]
        \centering 
        \label{fig:Aigpred} 
        \includegraphics[width=3in,heigth=3in,angle=270]{Aigpred} 
        \caption{\it Prédiction du cours pour la période entre 2014-11-24 et
        2015-01-08  } 
    \end{figure} 

    En particulier le cours de AIG pour demain 10-01-2014 sera dans
    l'intervalle \verb+[53.11062,55.42253]+ avec une confiance 95\% et une
    estimation de \verb+54.25426+
    \paragraph{Prédiction à un horizon} 
        On va prédire maintenant à partir de la date 2014-11-24 les 5 prochaines
        dates de cotations :
        \begin{figure}[H]
            \centering 
            \label{fig:Aigpred2} 
            \includegraphics[width=3in,heigth=3in,angle=270]{Aigpred2} 
            \caption{\it Prédiction à partir de la date 2014-11-24 } 
        \end{figure} 
        \section{Cointégration}
    \paragraph{} Le cours d'action et de la société AIG et ses spreads de CDS étant
    étroitement liées on va cointegrer ses deux séries entre les dates
    2008-09-05 et 2009-10-30. Ici nous notons $X_t$ le cours d'action AIG et
    $Y_t$ le spreads CDS de AIG.
    \paragraph{Étude du résidu de la régression} Notre première étape est de faire
    une régression du $Y_t$ sur $X_t$ :
    \begin{figure}[H]
        \centering 
        \label{fig:coreg} 
        \includegraphics[width=3in,heigth=3in,angle=270]{coreg} 
        \caption{\it Régression linéaire des Spreads sur le cours d'action } 
    \end{figure}
    \paragraph{Étude du résidu}
    \begin{figure}[H]
          \centering 
         \label{fig:depreg} 
          \includegraphics[width=3in,heigth=3in,angle=270]{depreg} 
          \caption{\it Corrélogramme du résidu de la régression } 
            \end{figure} 
             
            \paragraph{} on constate que le résidu n'est pas stationnaire.

            \paragraph{Différenciation du résidu} procédons a la différenciation
            d'ordre 3 :
            \begin{figure}[H]
                \centering 
                \label{fig:depd3reg} 
                \includegraphics[width=3in,heigth=3in,angle=270]{depd3reg} 
                \caption{\it Corrélogramme du résidu différencie à l'ordre 3 } 
            \end{figure} 
            On remarque que l'ACF s'annule à partir du 3 ème retard et que
            l'PACF décroit exponentiellement donc il s'agit d'un ARIMA(p,3,2).
            Par ailleurs on constate que ARIMA(1,3,2) est celui qui minimise
            AIC.
            
            \begin{figure}[H]
                \centering 
                \label{fig:depd3rr} 
                \includegraphics[width=3in,heigth=3in,angle=270]{depd3rr} 
                \caption{\it Corrélogramme du résidu de notre modélisation ARIMA(1,3,2) } 
            \end{figure} 

            Le processus ne montre aucune autocorrélation non nulle, ceci appuis
            l'hypothèse de stationnarité :
            \begin{verbatim}
            > summary(ur.kpss(rr))

            ####################### 
            # KPSS Unit Root Test # 
            ####################### 

            Test is of type: mu with 5 lags. 

            Value of test-statistic is: 0.1409 

            Critical value for a significance level of: 
                            10pct  5pct 2.5pct  1pct
            critical values 0.347 0.463  0.574 0.739
            \end{verbatim}
            Le test de KPSS montre aussi que le processus est stationnaire car
            la valeur du test est inférieur aux valeurs critiques. D'autre part
            le résidu est centre :
            \begin{verbatim}
            > t.test(rr)

                One Sample t-test

                data:  rr
                t = 0.0255, df = 288, p-value = 0.9796
                alternative hypothesis: true mean is not equal to 0
                95 percent confidence interval:
                 -0.1896448  0.1946299
                sample estimates:
                mean of x 
                0.002492546 
            \end{verbatim}
            Le test de Student confirme bien que le résidu est centre et
            gaussien. En effet le graphe de probabilité de la loi normale est
            parfaitement linéaire :
            \begin{figure}[H]
                \centering 
                \label{fig:qqrr} 
                \includegraphics[width=3in,heigth=3in,angle=270]{qqrr} 
                \caption{\it QQ-plot du résidu pour la loi normale } 
            \end{figure} 

            \paragraph{Indépendance}
            Le processus est indépendant car il est gaussion de fonction
            d'autocorrélation nulle.
            \paragraph{Conclusion} Notre modélisation du résidu en arima est
            vérifiée, en notant le résidu par $(r_t)$ :
            \begin{equation}
                Y_t &=& -0.04 X_t + 28.74 + r_t \\
                Z_t &=& \Delta^{3}r_t \\
                Z_t + a_1 Z_{t-1} &=& \epsilon_t + b_1 \epsilon_{t-1} + b_2
                \epsilon_{t-2}\\
                \epsilon_t \sim \mathcal{N}(0,2.75) &=& 
     
                \label{eq:1}
            \end{equation}
                       
            Ainsi les séries $X_t,Y_t$ sont cointegrer car $Z_t$ est un
            processus intégré d'ordre 3.
